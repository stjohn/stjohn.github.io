<!DOCTYPE doctype PUBLIC "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
  <meta http-equiv="Content-Type"
 content="text/html; charset=iso-8859-1">
  <title>Coursework, CSci 39542: Data Science, Hunter College</title>
</head>
<STYLE>A {text-decoration: none;}
th, td { padding: 5px; }
code {
  background-color: #eeeeee;
}
.inline {
  padding: 1px;
}
.blockcode {
  border: 1px solid #999999;
  display: block;
  padding-left: 10px;
  padding-top : 2px;
  padding-bottom : 2px;
  margin: 5px;
}
.datablock {
  border: 1px solid #eeeeee;
  display: block;
  padding: 7px;
  padding-top : 0px;
  margin: 5px;
}
</STYLE>
<body>


<div style="margin: 15px;width=100%;">
    <span style= "float: left;font-size:larger"><a href="index.html">CSci 39542</a></span>
    <span style= "float: right">
      <a href="syl.html">Syllabus</a>&nbsp;&nbsp;&nbsp;
      <a href="resources.html">Resources</a>&nbsp;&nbsp;&nbsp;
      <a href="work.html">Coursework</a><!--&nbsp;&nbsp;&nbsp;
      <a href="faq.html">FAQ</a>-->
    </span>
</div>

<br>
<br>
<hr>

<div style="margin:50px">


<h2>Coursework
  <br>CSci 39542: Introduction to Data Science<br>
<a href="http://www.hunter.</i>cuny.edu/csci">Department of Computer Science</a><br>
<a href="https://hunter.</i>cuny.edu">Hunter College</a>, <a href="https://www.cuny.edu">City University of New York</a><br>
Fall 2021<br><br>
</h2>


<hr>
<a href="work.html#quizzes">Quizzes</a>&nbsp;&nbsp;&nbsp;
<a href="work.html#hw">Homework</a>&nbsp;&nbsp;&nbsp;
<a href="work.html#project">Project</a>&nbsp;&nbsp;&nbsp;
<hr>

<a name="quizzes">
<h2>Quizzes</h2>
</a>
Unless otherwise noted, quizzes are available on Blackboard for the 24 hours after lecture.  Blackboard quizzes are 15 minutes long and can be repeated up to the deadline.  The highest score earned on a Blackboard quiz will be reported.  Blackboard access is generated automatically from the registrar.  See the ICIT <a href="http://www.hunter.</i>cuny.edu/it/blackboard/student-documentation-and-support-for-blackboard">Blackboard</a> page for resources and tutorials for using the system.

<p> Five of the quizzes assess your programming skill using HackerRank.  These quizzes are 30 minutes long and cannot be repeated.  Links will be available on Blackboard to access the quiz.

<p>
There are no make-up quizzes. Instead, your score on the final exam will replace missing quiz grades (the final exam will also replace a quiz grade when you take the quiz but do better on the final exam).  See the <a href="syl.html">syllabus</a> for additional information on how grades are calculated.

<p><a name="q1"><b>Quiz 1: </b> &emsp; <i>Due 4pm, Friday, 27 August.</i>
  The first quiz asks that you confirm that you have read the Hunter College's
  <a href="http://www.hunter.</i>cuny.edu/studentaffairs/student-conduct/academic-integrity/welcome-academic-integrity/?searchterm=integrity">Academic Integrity Policy</a>:
  <blockquote>
  <i>
  Hunter College regards acts of academic dishonesty (e.g., plagiarism, cheating on examinations, obtaining unfair advantage, and falsification of records and official documents) as serious offenses against the values of intellectual honesty. The College is committed to enforcing the CUNY Policy on Academic Integrity and will pursue cases of academic dishonesty according to the Hunter College Academic Integrity Procedures.</i>
  </blockquote>
</p>

<p><a name="q2"><b>Quiz 2: </b></b> &emsp; <i>Due 4pm, Tuesday, 31 August. </i>&emsp;
  The second quiz focuses on the Python Recap: basics and standard packages (pandas, numpy,  matplotlib, & seaborn), zips, and list comprehensions from Lecture 1.</p>

<p><a name="q3"><b>Quiz 3: </b></b> &emsp; <i>Due 4pm, Friday, 3 September.</i>&emsp;
  The quiz covers data sampling from the third lecture and the reading: <a href="http://www.textbook.ds100.org/ch/02/design_intro.html">DS 100: Chapter 2</a> (Design Intro) and includes Python review questions.</p>

<p><a name="q4"><b>Quiz 4: </b></b> &emsp; <i>Due 4pm, Friday, 10 September.</i>&emsp;
  The quiz covers Python string methods and Python data types from the second and third lectures and the reading: <a href="http://www.textbook.ds100.org/ch/12/text_strings.html">DS 100: Section 13.1</a> (Python String Methods)
  and subsetting dataframes from <a href="http://www.textbook.ds100.org/ch/06/pandas_intro.html">DS 100: Chapter 7</a> (Data Tables in Python).
</p>

<strike>
<p><a name="q5"><b>Quiz 5: </b></b> &emsp; <i>Due 4pm, Tuesday, 14 September.</i>&emsp;
  This is a <b>coding quiz on HackerRank</b> focusing on the Python constructs and package from the first two weeks. You will be sent an invitation to the email you use for Gradescope for this quiz.  You have 30 minutes to complete the quiz, and the quiz cannot be repeated.
</strike>

<p><a name="q6"><b>Quiz 6: </b></b> &emsp; <i>Due 4pm, Tuesday, 21 September.</i>&emsp;
  Today's topic is regular expressions from Lecture #3 and <a href="http://www.textbook.ds100.org/ch/12/text_regex.html">DS 100: Sections 13.2-13.3</a> (Regular Expressions).</p>

<p><a name="q7"><b>Quiz 7: </b></b> &emsp; <i>Due 4pm, Friday, 24 September.</i>&emsp;
  This quiz covers SQL from Lectures #4, 5 & 6 and <a href="http://www.textbook.ds100.org/ch/05/sql_intro.html">DS 100: Chapter 6</a> (Relational Databases & SQL).</p>

<p><a name="q8"><b>Quiz 8: </b></b> &emsp; <i>Due 4pm, Tuesday, 28 September.</i>&emsp;
  This quiz covers DataFrames from Pandas, covered in Lectures #4, 5 & 6 and <a href="http://www.textbook.ds100.org/ch/06/pandas_intro.html">DS 100: Chapter 7</a> (Data Tables in Python).</p>

<p><a name="q9"><b>Quiz 9: </b></b> &emsp; <i>Due 4pm, Friday, 1 October.</i>&emsp;
    The focus is functions in Python, covered in the code demos in Lectures #5 and #6.</p>

<p><a name="q10"><b>Quiz 10: </b></b> &emsp; <i>Due 4pm, Tuesday, 5 October.</i>&emsp;
  This is a <b>coding quiz on HackerRank</b>. You will be sent an invitation to the email you use for Gradescope for this quiz.  You have 30 minutes to complete the quiz, and the quiz cannot be repeated.</p>

<p><a name="q11"><b>Quiz 11: </b> &emsp; <i>Due 4pm, Friday, 8 October.</i>&emsp;
  The focus in on data visualiation as discussed in Lectures #10 and #11 and <a href="http://www.textbook.ds100.org/ch/10/viz_intro.html">DS 100: Chapter 11</a> (Data Visualization).</p>

<p><a name="q12"><b>Quiz 12: </b> &emsp; <i>Due 4pm, Friday, 15 October.</i>&emsp;
  The quiz covers loss functions from Lectures #10 & #11 and the reading: <a href=
  "http://www.textbook.ds100.org/ch/03/modeling_loss_functions.html">DS 100, Sections 3.2-3.4</a> (Loss Functions).



<p><a name="q13"><b>Quiz 13: </b> &emsp; <i>Due 4pm, Tuesday, 19 October.</i>&emsp;
  The focus of this quiz is probability and risk, covered in Lecture #12,
  <a href="https://inferentialthinking.com/chapters/09/Randomness.html">DS 8: Chapter 9</a> (Randomness), and
    <a href="http://www.textbook.ds100.org/ch/15/prob_and_gen.html">DS 100: Chapter 16</a> (Probability & Generalization).
</p>

<p><a name="q14"><b>Quiz 14: </b> &emsp; <i>Due 4pm, Friday, 22 October.</i>&emsp;
  The quiz covers gradient descent from Lecture #13 and the reading: <a href= "http://www.textbook.ds100.org/ch/16/gradient_descent.html">DS 100: Chapter 17</a> (Gradient Descent).

</p>
<p><a name="q15"><b>Quiz 15: </b> &emsp; <i>Due 4pm, Tuesday, 26 October.</i>&emsp;
  This is a <b>coding quiz on HackerRank</b>. You will be sent an invitation to the email you use for Gradescope for this quiz.  You have 30 minutes to complete the quiz, and the quiz cannot be repeated.
</p>

<!--
<p><a name="q16"><b>Quiz 16: </b> &emsp; <i>Due 4pm, Friday, 29 October.</i>&emsp;
</p>
<p><a name="q17"><b>Quiz 17: </b> &emsp; <i>Due 4pm, Tuesday, 2 November.</i>&emsp;
</p>
<p><a name="q18"><b>Quiz 18: </b> &emsp; <i>Due 4pm, Friday, 5 November.</i>&emsp;
</p>
<p><a name="q19"><b>Quiz 19: </b> &emsp; <i>Due 4pm, Tuesday, 9 November.</i>&emsp;
</p>
<p><a name="q20"><b>Quiz 20: </b> &emsp; <i>Due 4pm, Friday, 12 November.</i>&emsp;
    This is a <b>coding quiz on HackerRank</b>. You will be sent an invitation to the email you use for Gradescope for this quiz.  You have 30 minutes to complete the quiz, and the quiz cannot be repeated.<p>
</p>
<p><a name="q21"><b>Quiz 21: </b> &emsp; <i>Due 4pm, Tuesday, 16 November.</i>&emsp;
</p>
<p><a name="q22"><b>Quiz 22: </b> &emsp; <i>Due 4pm, Friday, 19 November.</i>&emsp;
</p>
<p><a name="q23"><b>Quiz 23: </b> &emsp; <i>Due 4pm, Tuesday, 23 October.</i>&emsp;
</p>
<p><a name="q24"><b>Quiz 24: </b> &emsp; <i>Due 4pm, Tuesday, 30 November.</i>&emsp;
</p>
<p><a name="q25"><b>Quiz 25: </b> &emsp; <i>Due 4pm, Friday, 3 December.</i>&emsp;
        This is a <b>coding quiz on HackerRank</b>. You will be sent an invitation to the email you use for Gradescope for this quiz.  You have 30 minutes to complete the quiz, and the quiz cannot be repeated.<p>
</p>
<p><a name="q26"><b>Quiz 26: </b> &emsp; <i>Due 4pm, Tuesday, 7 December.</i>&emsp;
</p>
<p><a name="q77"><b>Quiz 27: </b> &emsp; <i>Due 4pm, Friday, 9 December.</i>&emsp;
</p>
<p><a name="q28"><b>Quiz 28: </b> &emsp; <i>Due 4pm, Tuesday, 14 December.</i>&emsp;
  End of semester survey.
</p>

-->


<p>
  <i>More to come...</i>

<!--
  This quiz covers data representation from Lecture #5 and <a href=
  "http://www.textbook.ds100.org/ch/07/repr_intro.html">DS 100, Chapter 7</a> (Data Representation).</p>

-->
<br><br><br><br>
<hr>

<a name="hw">
<h2>Homework</h2>
</a>
Unless otherwise noted, programs are submitted on the course's Gradescope site and are written in Python.
Also, to receive full credit, the code should be compatible with Python 3.6 (the default for the Gradescope autograders).

<p>All students registered by Monday, 23 August were sent a registration invitation to the email on record on their Blackboard account.  If you did not receive the email or would like to use a different account, post to <code class="inline">Help::Individual Questions</code> (on the left hand menu when logged into the course site on Blackboard).  Include in your post that you not receive a Gradescope invitation, your preferred email, and we will manually generate an invitation.  As a default, we use your name as it appears in Blackboard/CUNYFirst (to update CUNYFirst, see <a href="https://hunter.</i>cuny.edu/students/registration/records-and-transcripts/changing-your-personal-information/">changing your personal information</a>).  If you prefer a different name for Gradescope, include it in your post, and we will update the Gradescope registration.



<p>
To get full credit for a program, the file must include in the opening comment:
<ul>
    <li> Your name, as it appears in your Gradescope registration.
    <li> The email you are using for Gradescope.
    <li> A list of any resources you used for the program.  Include classmates and tutors that you worked with, along with any websites or tutorials that you used.  If you used no resources (other than the class notes and textbooks), then you should include the line:  "No resources used."
</ul>

For example, for the student, Thomas Hunter, the opening comment of his first program might be:
<pre><code class="blockcode">
"""
Name:  Thomas Hunter
Email: thomas.hunter.</i>1870@hunter.</i>cuny.edu
Resources:  Used python.org as a reminder of Python 3 print statements.
"""
</pre></code>
and then followed by his Python program.

<br>
<br>
<br>
<hr>
Set 1:  The first set of programs recaps familiar Python constructs and packages.  None are challenging, instead, their purpose is as review and to ensure your Python IDE is functional, has the basic libraries and that you can submit programs to Gradescope.
<hr>

<p><a name="p1"><b>Program 1: Hello, world.</b></b> &emsp; <i>Due noon, Friday, 27 August.</i>
  <br>(Learning Objective:  students are able to use a Python IDE on their computer and successfully submit the work to the Gradescope system.)

  <p>Submit a Python program that prints:  <code class = "inline">Hello, world</code>
</p>

<p><a name="p2"><b>Program 2: Senators' Names.</b></b> &emsp; <i>Due noon, Monday, 30 August.</i>
  <br>(Learning Objective: students can successfully read and write CSV files and use the Pandas package to select rows, filtered by boolean expressions.)

  <p>
Write a program, using the <code class = "inline">pandas</code> package, that asks the user for the name of an input CSV file and the name of an output CSV file.  The program should open the file name provided by the user.
Next, the program should select rows where the field <code class = "inline">senate_class</code> is non-empty and write the <code class = "inline">first_name</code> and <code class = "inline">last_name</code> to a file with the output file name provided by the user.

<p>For example, if the file was <a href="https://theunitedstates.io/congress-legislators/legislators-current.csv">legislators-current.csv</a> with the first 3 lines of:
<pre><code class=datablock>
last_name,first_name,middle_name,suffix,nickname,full_name,birthday,gender,type,state,district,senate_class,party,url,address,phone,contact_form,rss_url,twitter,facebook,youtube,youtube_id,bioguide_id,thomas_id,opensecrets_id,lis_id,fec_ids,cspan_id,govtrack_id,votesmart_id,ballotpedia_id,washington_post_id,icpsr_id,wikipedia_id
Brown,Sherrod,,,,Sherrod Brown,1952-11-09,M,sen,OH,,1,Democrat,https://www.brown.senate.gov,503 Hart Senate Office Building Washington DC 20510,202-224-2315,http://www.brown.senate.gov/contact/,http://www.brown.senate.gov/rss/feeds/?type=all&amp;,SenSherrodBrown,SenatorSherrodBrown,SherrodBrownOhio,UCgy8jfERh-t_ixkKKoCmglQ,B000944,00136,N00003535,S307,"H2OH13033,S6OH00163",5051,400050,27018,Sherrod Brown,,29389,Sherrod Brown
Cantwell,Maria,,,,Maria Cantwell,1958-10-13,F,sen,WA,,1,Democrat,https://www.cantwell.senate.gov,511 Hart Senate Office Building Washington DC 20510,202-224-3441,http://www.cantwell.senate.gov/public/index.cfm/email-maria,http://www.cantwell.senate.gov/public/index.cfm/rss/feed,SenatorCantwell,senatorcantwell,SenatorCantwell,UCN52UDqKgvHRk39ncySrIMw,C000127,00172,N00007836,S275,"S8WA00194,H2WA01054",26137,300018,27122,Maria Cantwell,,39310,Maria Cantwell
</code></pre>

Then a sample run of the program:

<pre><code class="blockcode">Enter input file name: legislators-current.csv
Enter output file name:  senatorNames.csv
</code></pre>

And the first three lines of <code class = "inline">senatorNames.csv</code> would be:
<pre><code class=datablock>
first_name,last_name
Sherrod,Brown
Maria,Cantwell
</code></pre>

Note:  if you use the legislators CSV file above, your output file should have 101 lines:  1 line of header information and 100 rows of data.
<br>

<p><a name="p3"><b>Program 3: Senators' Ages.</b></b> &emsp; <i>Due noon, Wednesday, 1 September.</i>
  <br>(Learning Objective: to refresh students' knowledge of Pandas' functionality to create new columns from existing columns of formatted data.)</p><p>
Write a program that asks the user for the name of an input CSV file and the name of an output CSV file.  The program should open the file name provided by the user.</i>  Next, the program should select rows where the field <code class = "inline">senate_class</code> is non-empty and write the <code class = "inline">first_name</code> and compute the <code class = "inline">age</code> based on the <code class = "inline">birthday</code> field as of the first of the year.  Your program should write out a new CSV file (with the name provided by the user) with the two columns:  <code class = "inline">first_name</code> and <code class = "inline">age</code>.

<p>For example, if the file was <a href="https://theunitedstates.io/congress-legislators/legislators-current.csv">legislators-current.csv</a> with the first 3 lines of:

<pre><code class="datablock">
last_name,first_name,middle_name,suffix,nickname,full_name,birthday,gender,type,state,district,senate_class,party,url,address,phone,contact_form,rss_url,twitter,facebook,youtube,youtube_id,bioguide_id,thomas_id,opensecrets_id,lis_id,fec_ids,cspan_id,govtrack_id,votesmart_id,ballotpedia_id,washington_post_id,icpsr_id,wikipedia_id
Brown,Sherrod,,,,Sherrod Brown,1952-11-09,M,sen,OH,,1,Democrat,https://www.brown.senate.gov,503 Hart Senate Office Building Washington DC 20510,202-224-2315,http://www.brown.senate.gov/contact/,http://www.brown.senate.gov/rss/feeds/?type=all&amp;,SenSherrodBrown,SenatorSherrodBrown,SherrodBrownOhio,UCgy8jfERh-t_ixkKKoCmglQ,B000944,00136,N00003535,S307,"H2OH13033,S6OH00163",5051,400050,27018,Sherrod Brown,,29389,Sherrod Brown
Cantwell,Maria,,,,Maria Cantwell,1958-10-13,F,sen,WA,,1,Democrat,https://www.cantwell.senate.gov,511 Hart Senate Office Building Washington DC 20510,202-224-3441,http://www.cantwell.senate.gov/public/index.cfm/email-maria,http://www.cantwell.senate.gov/public/index.cfm/rss/feed,SenatorCantwell,senatorcantwell,SenatorCantwell,UCN52UDqKgvHRk39ncySrIMw,C000127,00172,N00007836,S275,"S8WA00194,H2WA01054",26137,300018,27122,Maria Cantwell,,39310,Maria Cantwell
</code></pre>

Then a sample run of the program:
<pre><code class="blockcode">Enter input file name: legislators-current.csv
Enter output file name:  senatorAge.csv
</code></pre>

And the first three lines of <code class="inline">senatorAge.csv</code> would be:
<pre><code class="datablock">
first_name,age
Sherrod,68
Maria,62
</code></pre>
since that was their ages as of the start of the year:  January 1, 2021.
<p>
Note:  if you use the legislators CSV file above, your output file should have 101 lines:  1 line of header information and 100 rows of data.
<br>

<p><a name="p4"><b>Program 4: ELA Proficiency.</b></b> &emsp; <i>Due noon, Thursday, 2 September.</i>
  <br>(Learning Objective: students can successfully filter formatted data using standard Pandas operations for selecting data.)

  <p>
  Write a program that asks the user for the name of an input CSV file and the name of an output CSV file.  The program should open the file name provided by the user.
  Next, the program should select rows where the field <code class="inline">Grade</code> is equal to 3 and the <code class="inline">Year</code> is equal to 2019 and write all rows that match that criteria to a new CSV file.

  <p>
  Then a sample run of the program:
<pre><code class="blockcode">Enter input file name: school-ela-results-2013-2019.csv
Enter output file name:  ela2013.csv
</code></pre>
  where the file <code class="inline">school-ela-results-2013-2019.csv</code> is extracted from <a href="https://infohub.nyced.org/reports/academics/test-results">NYC Schools Test Results</a> (and <a href="school_ELA_2013_2019_truncated.csv">truncated version</a> of roughly the first 1000 lines for testing).  The first lines of the output file would be:

<pre><code class="datablock">
School,Name,Grade,Year,Category,Number Tested,Mean Scale Score,# Level 1,% Level 1,# Level 2,% Level 2,# Level 3,% Level 3,# Level 4,% Level 4,# Level 3+4,% Level 3+4
01M015,P.S. 015 ROBERTO CLEMENTE,3,2019,All Students,27,606,1,3.7,7,25.9,18,66.7,1,3.7,19,70.4
01M019, P.S. 019 ASHER LEVY,3,2019,All Students,24,606,0,0.0,8,33.3,15,62.5,1,4.2,16,66.7
01M020,P.S. 020 ANNA SILVER,3,2019,All Students,57,593,13,22.8,24,42.1,18,31.6,2,3.5,20,35.1
</code></pre>

<br>
<br>
<br>
<hr>
  Set 2:  The second set of programs focuses on incorporating and analyzing rectangular data, in terms of relational databases and data frames.  The goal is familiarity with these canonical representations to use as building blocks for future analysis, programs, and your project.
<hr>

<p><a name="p5"><b>Program 5: URL Collection.</b></b> &emsp; <i>Due noon, Friday, 3 September.</i>
  <br>(Learning Objective: to use regular expressions with simple patterns to filter column data in a canonical example: scraping a website of URL's.)

  <p>
  Write a program that asks the user for the name of an input HTML file and the name of an output CSV file.  Your program should use regular expressions (see <a href="http://www.textbook.ds100.org/ch/12/text_re.html">Chapter 12.4</a> for using the <code class="inline">re</code> package in Python) to find all links in the input file and store the link text and URL as columns:  <code class="inline">Title</code> and <code class="inline">URL</code> in the CSV file specified by the user.  For the URL, strip off the leading <code class="inline">https://</code> or <code class="inline">http://</code> and any trailing slashes (<code class="inline">/</code>):

  <p>For example, if the input file is:

<pre><code class="datablock">
  &lt;html>
  &lt;head>&lt;title>Simple HTML File&lt;/title>&lt;/head>

  &lt;body>
    &lt;p> Here's a link for &lt;a href="http://www.hunter.</i>cuny.edu/csci">Hunter CS Department&lt;/a>
    and for &lt;a href="https://stjohn.github.io/teaching/data/fall21/index.html">CSci 39542&lt;/a>.  &lt;/p>

    &lt;p> And for &lt;a href="https://www.google.com/">google&lt;/a>
  &lt;/body>
  &lt;/html>
</code></pre>

  Then a sample run of the program:
<pre><code class="blockcode">Enter input file name: simple.html
Enter output file name:  links.csv
</code></pre>

  And the <code class="inline">links.csv</code> would be:
<pre><code class="datablock">
Title,URL
Hunter CS Department,www.hunter.</i>cuny.edu/csci
CSci 39542,stjohn.github.io/teaching/data/fall21/index.html
google,www.google.com</code></pre>
</p>
  <br>

</p>

<i>Program 6 is cancelled.  See announcement on Blackboard.</i>
<strike>
<p><a name="p6"><b>Program 6: Regex on Restaurant Inspection Data.</b></b> &emsp; <i>Due noon, Thursday, 9 September.</i>
  <br>(Learning Objective: The two learning objectives of this exercise are a) to give the students an opportunity to practice their newfound regular expressions (regex) skills and b) familiarize them with the restaurant inspection dataset which would be used again in the latter SQL programs.)

  <p>
  Use regular expressions (covered in Lecture 3 & <a href="http://www.textbook.ds100.org/ch/12/text_regex.html">DS 100: Sections 12.2-3</a>) to clean <a href="https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j/data">restaurant inspection</a> datasets that we will use in later SQL programs.

  <!--
  <i>Add in small dataset to use for testing</i>
  Add in sample run: either as functions or as the resulting CSV.
  Process:
1. Take input csv_file_name and output_file_name,
2. run requested operations on the input data and save it into a csv file under the output_file_name,
3. save work into new csv.
  -->
  Your program should:
  <ul>
    <li> Ask the user for names of an input file and output file.  You can assume that the input file is a CSV file with column names from the <a href="https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j/data">restaurant inspection</a> datasets.  Your program should open the named CSV input file and save the results in the named output file.

    <li>There are many invalid phone numbers in the data set. Instead of 10 digits, e.g. <code class="inline">2125551212</code>, some entries have extra characters and not enough digits, e.g. <code class="inline">212-555-12</code>.  First, use regex to check that 10 digits were entered.  If not, set the value to <code class="inline">""</code> (empty string) since the current data is corrupt.  If the phone number does have 10 digits, use regex to parse out the given 10 digit phone number <code class="inline">DDDDDDDDDD</code> and re-concatenate it back into a 11 digit format: 1-digit country code (as 1), 3-digit area code, and a 7-digit telephone number, so that the final output looks like: <code class="inline">+1-DDD-DDD-DDDDD</code>.

    <li> With the inspection date column, use regex to break out the year, month, and day component, then re concatenate the <code class="inline">MM/DD/YYYY</code> to <code class="inline">YYYY/MM/DD</code>.

    <li> With the restaurant name column <code class="inline">DBA</code>, please create a new column called "restaurant_name" which reformats the data in the original column from all upper case to camel case. Separately, create a new Boolean column that flags <code class="inline">True</code> if the word <code class="inline">Thai</code> (not case sensitive) appears in the original restaurant name.
  </ul>

  <p>For example, if the file was <a href="restaurants30July.csv">restaurants30July.csv</a> with the first 3 lines of:

  <pre><code class="datablock">
CAMIS,DBA,BORO,BUILDING,STREET,ZIPCODE,PHONE,CUISINE DESCRIPTION,INSPECTION DATE,ACTION,VIOLATION CODE,VIOLATION DESCRIPTION,CRITICAL FLAG,SCORE,GRADE,GRADE DATE,RECORD DATE,INSPECTION TYPE,Latitude,Longitude,Community Board,Council District,Census Tract,BIN,BBL,NTA
41178124,CAFE 57,Manhattan,300,WEST   57 STREET,10019,2126492729,American,7/30/2021,Violations were cited in the following area(s).,09C,Food contact surface not properly maintained.,Not Critical,4,A,7/30/2021,8/1/2021,Cycle Inspection / Initial Inspection,40.76643902,-73.98332508,104,3,13900,1025451,1010477502,MN15
50111450,CASTLE CHICKEN,Bronx,5987A,BROADWAY,10471,9178562047,Chicken,7/30/2021,Violations were cited in the following area(s).,05D,Hand washing facility not provided in or near food preparation area and toilet room. Hot and cold running water at adequate pressure to enable cleanliness of employees not provided at facility. Soap and an acceptable hand-drying device not provided.,Critical,41,N,,8/1/2021,Pre-permit (Operational) / Initial Inspection,40.88993027,-73.89805316,208,11,28500,2084208,2058011033,BX29
40699339,NICK GARDEN COFFEE SHOP,Bronx,2953,WEBSTER AVENUE,10458,7183652277,Coffee/Tea,7/30/2021,Violations were cited in the following area(s).,08A,Facility not vermin proof. Harborage or conditions conducive to attracting vermin to the premises and/or allowing vermin to exist.,Not Critical,31,,,8/1/2021,Cycle Inspection / Initial Inspection,40.86759042,-73.88308647,207,11,41500,2016446,2032800061,BX05
</code></pre>

  Then a sample run of the program:
  <pre><code class="blockcode">
Enter input file name: restaurants30July.csv
Enter output file name:  july30filtered.csv
  </code></pre>

  And the first three lines of <code class="inline">july30filtered.csv</code> would be:
<pre><code class="datablock">
CAMIS,DBA,BORO,BUILDING,STREET,ZIPCODE,PHONE,CUISINE DESCRIPTION,INSPECTION DATE,ACTION,VIOLATION CODE,VIOLATION DESCRIPTION,CRITICAL FLAG,SCORE,GRADE,GRADE DATE,RECORD DATE,INSPECTION TYPE,Latitude,Longitude,Community Board,Council District,Census Tract,BIN,BBL,NTA,restaurant_name,thai_boolean
41178124,CAFE 57,Manhattan,300,WEST  57 STREET,10019,+1-212-649-2729,American,2021/07/30,Violations were cited in the following area(s).,09C,Food contact surface not properly maintained.,Not Critical,4,A,7/30/2021,8/1/2021,Cycle Inspection / Initial Inspection,40.76643902,-73.98332508,104,3,13900,1025451,1010477502,MN15,Cafe 57 ,False
50111450,CASTLE CHICKEN,Bronx,5987A,BROADWAY,10471,+1-917-856-2047,Chicken,2021/07/30,Violations were cited in the following area(s).,05D,Hand washing facility not provided in or near food preparation area and toilet room. Hot and cold running water at adequate pressure to enable cleanliness of employees not provided at facility. Soap and an acceptable hand-drying device not provided.,Critical,41,N,,8/1/2021,Pre-permit (Operational) / Initial Inspection,40.88993027,-73.89805316,208,11,28500,2084208,2058011033,BX29,Castle Chicken ,False
40699339,NICK GARDEN COFFEE SHOP,Bronx,2953,WEBSTER AVENUE,10458,+1-718-365-2277,Coffee/Tea,2021/07/30,Violations were cited in the following area(s).,08A,Facility not vermin proof. Harborage or conditions conducive to attracting vermin to the premises and/or allowing vermin to exist.,Not Critical,31,,,8/1/2021,Cycle Inspection / Initial Inspection,40.86759042,-73.88308647,207,11,41500,2016446,2032800061,BX05,Nick Garden Coffee Shop ,False
</code></pre>
</strike>


<p><a name="p7"><b>Program 7: Neighborhood Tabulation Areas</b></b> &emsp; <i>Due noon, Friday, 10 September.</i>
  <br>(Learning Objective: The learning objective of this exercise is to give the students an opportunity to practice their newfound SQL skills.)

  <p>
  The package <a href="https://pypi.org/project/pandasql/">pandasql</a> provides an easy way to use SQL queries directly on a Pandas DataFrame.  (You may need to install it in your hierarchy (e.g. <code class="inline">pip install pandasql</code> or <code class="inline">pip install pandasql</code>).

  <p>
  Once installed, you can run queries via the function  <code class="inline">sqldf(queryName)</code>.  For example, you could filter for all students in the <a href="https://raw.githubusercontent.com/DS-100/textbook/master/content/ch/01/roster.csv">roster.csv</a> on the waitlist by:

<pre><code class=blockcode>
import pandas as pd
import pandasql as psql
roster = pd.read_csv('roster.csv')

q = 'SELECT * FROM roster WHERE Role = "Waitlist Student"'
waitList = psql.sqldf(q)

print(waitList)
</code>
</pre>

  <p>For this program, ask the user for the input and output file names.
  You should assume that the input file contains the New York City
  <a href="https://data.cityofnewyork.us/City-Government/2010-Neighborhood-Tabulation-Areas-NTAs-/cpf4-rkhq">Neighborhood Tabulation Areas</a> such as
  <a href="nynta.csv">nynta.csv</a>.
  Use <code class="inline">sqldf(queryName)</code> to filter the dataset to return the <code class="inline">NTACode</code> and
  <code class="inline">NTAName</code> columns, labeled as
  <code class="inline">NTA</code> and <code class="inline">NTA_Name</code>, respectively.  You should save the result as a CSV in the output file named by the user.

<p><a name="p8"><b>Program 8: Restaurant SQL Queries.</b></b> &emsp; <i>Due noon, Monday, 13 September.</i>

  <p>Your program should ask for the input file name (must include .csv) and then for an output file prefix (must not include any extension). For example, with <code class="inline">restaurantJuly2020.csv</code> for the input and <code class="inline">selected</code> for the output prefix.  The program should create 4 files: <code class="inline">selectedA.csv</code>, <code class="inline">selected70.csv</code>, <code class="inline">selectedZIP.csv</code>, and <code class="inline">selectedAll.csv</code>.
  <p>
  Using SQL (see <a href="http://www.textbook.ds100.org/ch/05/sql_basics.html">DS 100: Section 5.2</a>), extract the following information from a <a href="https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j/data">restaurant inspection</a> dataset (a small file of inspections from 30 July is available: <a href="restaurants30July.csv">restaurants30July.csv</a>):
  <ul>
    <li> Save all rows in table where <code class="inline">Grade = A</code> to the output file <code class="inline">prefix+"A.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user.</i> <!--(note: warm-up for SELECT * FROM TABLE WHERE..)--> </li>
    <li> Save all rows in table where <code class="inline">SCORE > 70</code> to the output file <tt>prefix+"70.csv"</tt>.</li>
    <li> Save all rows in table where <code class="inline">ZIPCODE IN (10002, 10027, 10036)</code> to the output file <code class="inline">prefix+"ZIP.csv"</code></li>
    <li> Save columns
      <code class="inline">DBA</code> renamed as <code class="inline">restaurant_name</code>,
      <code class="inline">CUISINE DESCRIPTION</code> renamed as <code class="inline">cuisine_description</code>,
      <code class="inline">BORO</code> renamed as <code class="inline">borough</code>, and
      <code class="inline">GRADE</code> and select only those entries with:
      <code class="inline">GRADE = A</code> and <code class="inline">ZIPCODE IN (10002, 10027, 10036)</code> and save to the output file <code class="inline">prefix+"All.csv"</code>.
  </ul>

  <p>Note: The file extension names are case-sensitive, so, the autograder will not except <code class="inline">... ALL.csv</code> for <code class="inline">... All.csv</code>.
</p>



<p><a name="p9"><b>Program 9: Aggregating Restaurant Data (SQL).
  </b></b> &emsp; <i>Due noon, Tuesday, 14 September.</i>


  <br>(Learning Objective: The learning objective of this exercise is to give the students an opportunity to practice more advanced SQL skills (e.g. <code class="inline">GROUP BY</code>'s) on a familiar dataset.)

  <p>
  Using the more advanced SQL commands from <a href="http://www.textbook.ds100.org/ch/05/sql_basics.html">DS 100: Section 5.1</a> (e.g. <code class="inline">GROUP BY</code>'s), this program find distinct restaurant names and distinct cuisines by locale.  For testing, a small file of inspections from 1 August is available: <a href="brooklynJuly2021.csv">brooklynJuly2021.csv</a>.

  <p><p>Your program should ask for the input file name (must include .csv) and then for an output file prefix (must not include any extension).
  </p>
    <ul>
      <li> Save a unique column of distinct restaurants (note: return the restaurant names, not the count)  to the output file <code class="inline">prefix+"Restaurants.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user.</li>
      <li> Save a unique column of distinct cuisines (note: return the cuisine names, not the count) where <code class="inline">ZIPCODE = 11224</code> to the output file <code class="inline">prefix+"Cuisines11224.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user. </li>
      <li> Save 2 columns, the cuisine and the count of unique restaurants per cuisine,  where <code class="inline">ZIPCODE = 11224</code> (note: return the cuisine names, not the count) to the output file <code class="inline">prefix+"Counts11224.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user. </li>
      <li> Save 3 columns: the borough name, the unique count of cuisines per borough and the unique count of restaurants per boroughs. The results should be sorted results by the borough name (in ascending order:  <code class="inline">ASC</code>) and saved to the output file <code class="inline">prefix+"Boro.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user.</li>
    </ul>
    <p>
For example, if you entered <code class="inline">brooklynJuly2021.csv</code> and <code class="inline">selected</code> for the output prefix, the program should create 4 files: <code class="inline">selectedRestaurants.csv</code>, <code class="inline">selectedCuisines11224.csv</code>, <code class="inline">selectedCounts11224.csv</code>, and <code class="inline">selectedBoro.csv</code>.
The first several lines of <code class="inline">selectedRestaurants.csv</code> are:
<pre><code class=blockcode>DBA
1 HOTEL BROOKLYN BRIDGE
14 OLD FULTON STREET
98K
99 CENT PIZZA
ABURI SUSHI BAR
</code></pre>
</p>
<p>The file <code class="inline">selectedCuisines11224.csv</code> is:
<pre><code class=blockcode>cnt
American
</code></pre>
(since our test file only has restaurants that serve American food in the 11224 zipcode)
</p>
<p>The file <code class="inline">selectedCounts11224.csv</code> is:
<pre><code class=blockcode>CUISINE DESCRIPTION,COUNT(DISTINCT DBA)
American,3
</code></pre>
</p>
<p>The file <code class="inline">selectedBoro.csv</code> is:
<pre><code class=blockcode>borough,cnt_cuisine,cnt_restaurants
Brooklyn,50,384
</code></pre>
</p>

<p><a name="p10"><b>Program 10: Extracting Districts.</b></b> &emsp; <i>Due noon, Monday, 20 September.</i>
    <br>(Learning Objective: successfully write and apply functions to DataFrames to clean data.)
    <p>
    Write a program that asks the user for the name of an input CSV file and the name of an output CSV file.  The program should open the file name provided by the user. Your program should include a function, <code class="inline">extractDistrict()</code> that takes a string as an input and returns the number represented by the first two characters in the string:
    <pre><code class=blockcode>
    def extractDistrict(name):
    '''
    Extracts the district (first two characters) as an integer.
    Input:  Character string containing district + school num (e.g. "01M015")
    Returns:  The first characters as an integer (e.g. 1)
    '''

      #### Your code goes here ####
    </code>
    </pre>
    Your program should apply the function to each row that takes the first two characters of the <code class="inline">School</code> field, converts those into a digit, and stores the results in a new column, <code class="inline">District</code>.  That is,

    <pre><code class="blockcode">df['District'] = df['DBN'].apply(extractDistrict)</code></pre>

    <p> For example, if the <code class="inline">School</code> is <code class="inline">"01M015"</code>, the entry in the new column would be <code class="inline">1</code> (stored as a number, not a string).

    <p> The results should be written to a new CSV file, name provided by the user.</i></p>
  </p>



<p><a name="p11"><b>Program 11: Joining Restaurant & NTA Data.</b></b> &emsp; <i>Due noon, Tuesday, 21 September.</i>

  <br>(Learning Objective: The exercises in this program will build up to help students conceptualize and finally create a <code class="inline">JOIN</code> between the health inspection table and the NTA table.  This is to reinforce the learning done in the last 2 SQL lectures.)

  <p>For testing, a small file of inspections from 30 July is available: <a href="restaurants30July.csv">restaurants30July.csv</a> and the Neighborhood Tabulation Areas (NTA):
  <a href="nta.csv">nta.csv</a>.


  <p>Your program should ask for two input file name (must include .csv) and then for an output file prefix (must not include any extension). For example, with <code class="inline">restaurantJuly2020.csv</code> and <code class="inline">nta.csv</code> for the input and <code class="inline">selected</code> for the output prefix.  The program should create 6 files:
    <code class="inline">selected1.csv</code>,
    <code class="inline">selected2.csv</code>,
    <code class="inline">selected3.csv</code>,
    <code class="inline">selected4.csv</code>,
    <code class="inline">selected5.csv</code>, and
    <code class="inline">selected6.csv</code>.
  <p>
    <ol>
      <li> Save the NTA column from the restaurant inspection table to the output file <code class="inline">prefix+"1.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user.</i>
      <li> Save the count of unique NTAs in the restaurant health inspection table to the output file <code class="inline">prefix+"2.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user.  (Note this will have a single column and a single value.)
      <li> Save the NTA column and the count of the distinct restaurants from the restaurant inspection table to the output file <code class="inline">prefix+"3.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user.  (Hint:  how can you use <code class="inline">GROUP BY</code> to organize the output?)
      <li> Save the number of rows in the <b>NTA table</b> and the number of unique NTAs in the NTA table to the output file <code class="inline">prefix+"4.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user.
      (Note this will have a two rows and two columns.)
      <li> Save the names of the restaurant and its NTA which can be found via  a <code class="inline">LEFT JOIN</code> of the restaurant inspection table and NTA table.  Save the results to the output file <code class="inline">prefix+"5.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user.
      (Hint: join on the NTA code found in both (but using slightly different names).  Your output should have two columns.)
      <li> Building on the result from 5) above, keep the <code class="inline">LEFT JOIN</code> as is, do one more level of aggregation, so that the end result contains 3 columns (unique NTA code, unique NTA description, and the count distinct restaurants as grouped by the first 2 columns).  Save result to the output file <code class="inline">prefix+"6.csv"</code> where <code class="inline">prefix</code> holds the value specified by the user.
    </ol>
</p>



<p><a name="p12"><b>Program 12: MTA Ridership.</b></b> &emsp; <i>Due noon, Thursday, 23 September.</i>


  <br>(Learning Objective: to reinforce Pandas skills via use for data aggregating and data cleaning.)

  <p>In the next lecture, we will be summarizing time-series data and using a
  <a href="https://qri.cloud/nyc-transit-data/">cleaned version</a> of MTA subway and bus ridership, inspired by Oldenburg's <a href="https://observablehq.com/@benoldenburg/nyc-transit-turnstile-data">NYC Transit Turnstile Data</a>.

  <p>Write a program that asks the user for the name of an input CSV file and the name of an output CSV file.  The program should open the file name provided by the user, which you can assume will include the column names: <code class="inline">date</code>, <code class="inline">entries</code>, and <code class="inline">exit</code>.  You should create a new file that has one entry for each date that consists of the sum of all entries and the sum of all exits that occur on the date.  This aggegrate data should be stored in the output CSV and should contain only the three columns:  <code class="inline">date</code>, <code class="inline">entries</code>, and <code class="inline">exits</code>, even if there are additional columns in the input CSV file.</p>

  <p>
    <p>For example, if the file was the 2020 data for Staten Island, <a href="mta_trunc_staten_island.csv">rmta_trunc_staten_island.csv</a> with the first 3 lines of:

    <pre><code class="datablock">stop_name,daytime_routes,division,line,borough,structure,gtfs_longitude,gtfs_latitude,complex_id,date,entries,exits
St George,SIR,SIR,Staten Island,SI,Open Cut,-74.073643,40.643748,501,2020-01-01,2929,0
St George,SIR,SIR,Staten Island,SI,Open Cut,-74.073643,40.643748,501,2020-01-02,13073,0
St George,SIR,SIR,Staten Island,SI,Open Cut,-74.073643,40.643748,501,2020-01-03,11857,23
</code></pre>

    Then a sample run of the program:
    <pre><code class="blockcode">Enter input file name: mta_trunc_staten_island.csv
Enter output file name:  filteredSI.csv</code></pre>

    And the first three lines of <code class="inline">filteredSI.csv</code> would be:
  <pre><code class="datablock">date,entries,exits
2020-01-01,3128,0
2020-01-02,13707,0
2020-01-03,12507,23</code></pre>



<!-- URL of cleaned data:  https://qri.cloud/nyc-transit-data/turnstile_daily_counts_2020 and presented:  https://observablehq.com/@benoldenburg/nyc-transit-turnstile-data  -->



<br>
<br>
<br>
<hr>
Set 3:  The third set of programs integrates visualization techniques with analyzing structured data sets.  While the programs do not cover every visualization technique, the practice these programs provide will be directly relevant to your project.
<hr>

<p><a name="p13"><b>Program 13: Column Summaries.</b></b> &emsp; <i>Due noon, Friday, 24 September.</i>
  <br>(Learning Objective: to strengthen function-writing skills and examine alternate ways to summarize time-series data.)

  <p>In lecture, we used the Pandas' function, <code class = "inline">rolling()</code> to compute a 7-day average of subway ridership for the visualization of ridership in 2020.  For this program, write three functions that take as input a Pandas' series (e.g. a column of a DataFrame) that highlights different patterns in the data:</p>
  <ul>
    <li> <code class = "inline">cumulativeAverage(column)</code>:  Assumes the input is a Series of numerical data. Returns a Series with the cumulative (running) average of the values.  For example, if the first 5 entries are <code class = "inline">10,20,30,40,20</code>, the Series that is returned would start out as <code class = "inline">10,15,20,25,24</code> (since 10/1 = 10, (10+20)/2 = 15, (10+20+30)/3 = 20, (10+20+30+40)/4 = 25, (10+20+30+40+20)/5 = 24).  Note that it is different that <code class = "inline">rolling()</code> we used in class, since this function creates a value for all entries and averages across all values seen.
    <li> <code class = "inline">cyclicAverage(column)</code>:  Assumes the input is a Series of numerical data. Returns a Series with the average of the current day with, if they exist, the value from 7 days previously and 14 days previously.  That is, if they exist, for entry at index <code class = "inline">i</code>, take the average of the values at indices <code class = "inline">i</code>, <code class = "inline">i-1*offset</code>, and <code class = "inline">i-2*offset</code>, as the computation.  Since ridership is highly dependent on the day of the week, this averages the values of the same day in past weeks.
    <li> <code class = "inline">exponentialSmoothing(column)</code>:  Assumes the input is a Series of numerical data. Returns a Series with a weighted average of the previous values with the most recent values have higher weight and the older ones have lower weights.  The value for the first entry, <code class = "inline">newCol[0]</code> is <code class = "inline">column[0]</code>.  The value for subsequent entries is <code class = "inline">newCol[t+1] = 0.5*column[t+1] + 0.5*newCol[t]</code>.  For example, if we had the same Series starting the same as above, <code class = "inline">10,20,30,40,20</code>, our new column would start <code class = "inline">10,15,22.5,31.25,25.625</code>
    (since the first entry is the same, 0.5*20+0.5*10 = 15, 0.5*30+0.5*15= 22.5, 0.5*40+0.5*22.5 = 31.25, 0.5*20 + 0.5*31.25 = 25.625).
  </ul>
  Note:  you should submit a file with only the standard comments at the top, and these three functions.  The grading scripts will then import your functions for testing.
</p>

<p><a name="p14"><b>Program 14: Library Cleaning.</b></b> &emsp; <i>Due noon, Monday, 27 September.</i>
  <br>(Learning Objective: to strengthen data processing skills using regular expressions and standard string methods.)

  <p>
  Write two functions that will be used to clean the OpenData NYC dataset of <a href="https://data.cityofnewyork.us/Business/Library/p4pf-fyc4">Libraries in New York City</a> (downloaded as CSV file).  The first three lines of the CSV file look like:

<pre><code class="datablock">
the_geom,NAME,STREETNAME,HOUSENUM,CITY,ZIP,URL,BIN,BBL,X,Y,SYSTEM,BOROCODE
POINT (-73.95353074430393 40.80297988196676),115th Street,West 115th Street,203,New York,10026,http://www.nypl.org/locations/115th-street,1055236,1018310026,997115.12977,231827.652864,NYPL,1
POINT (-73.9348475633247 40.80301816141575),125th Street,East 125th Street,224,New York,10035,http://www.nypl.org/locations/125th-street,1054674,1017890037,1002287.604,231844.894956,NYPL,1
</code></pre>



  Each function takes as input a row of the table:
  <ul>
    <li> <code class = "inline">extractLatLon(row)</code>:  This function takes the values from the column <code class = "inline">the_geom</code> and extracts the longitude and latitude from the string (they are surrounded by parenthesis and separated by a space, and returns the two as numerical values.  For example, the function would return -73.95353074430393, 40.80297988196676 when applied to the first row of data.
    <li> <code class = "inline">extractTitle(row)</code>:  This function concatenates the values from the columns <code class = "inline">NAME</code>, <code class = "inline">CITY</code>, and <code class = "inline">ZIP</code> code into a single string, separated by a comma and space, and returns the string (to be used as the title for our visualizations).
    For example, when applying this function to the first data row, the return value would be:
    <code class = "inline">115th Street, New York, 10026</code>.
  </ul>

  <p>
  Note:  you should submit a file with only the standard comments at the top, and these two functions.  The grading scripts will then import your functions for testing.  A sample test program that assumes your program is called <code class = "inline">p14.py</code>
  and the CSV file is called <code class = "inline">LIBRARY.csv</code> is <a href="test14.py">test14.py</a>.

  </p>





<p><a name="p15"><b>Program 15: Plotting Challenge.</b></b> &emsp; <i>Due noon, Tuesday, 28 September.</i>


  <br>(Learning Objective: to explore and master <tt>matplotlib.pyplot</tt> commands to create data visualizations.)

  <p>
  The goal is to create a plot of <a href="https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95">NYC OpenData Motor Vehicle Collisions</a> that follows this <a href="https://www.dataquest.io/blog/making-538-plots/">style</a>.  For example, here is the plot for <a href="Motor_Vehicle_Collisions_Mar_2020.csv">January 2020</a> dataset:

  <p>
  <img src="col_Mar2020.png" height=300>

  <p>
  Your program should begin by asking the user for input and output files.  It should be written to take any dataset from the <a href="https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95">NYC OpenData Motor Vehicle Collisions</a> and produce an image that matches this <a href="https://www.dataquest.io/blog/making-538-plots/">style</a>.  The resulting image should be saved to the output file specified by the user.

  <p><i>Hint:  to transform the data into separate columns (i.e. "unstack"/pivot the groups to be columns) for the daily number of collisions for each borough:</i>
  <pre><code class="blockcode">boroDF = df.groupby(['BOROUGH','CRASH DATE']).count()['CRASH TIME'].unstack().transpose()
</code></pre>
  <i>where <tt>df</tt> is the DataFrame with the collisions data.</i></p>

</p>



<p><a name="p16"><b>Program 16:   Choropleth Attendance Cleaning.</b></b> &emsp; <i>Due noon, Thursday, 30 September.</i>
<br>(Learning Objective: to gain competency cleaning data using pandas functions.)

<p>In lecture, we wrote a program, <a href="schoolsChoropleth.py">schoolsChoropleth.py</a>, using the school district files used in <a href="#p10">Programs 10 & 11</a> to make a choropleth map of top English Languange Arts scores, by <a href="https://data.cityofnewyork.us/Education/School-Districts/r8nu-ymqj">district</a>, in New York City:

  <p>
  <iframe src="ela2019choropleth.html" style="width: 60%; height: 550px" name="internal"></iframe>


<p> For this program, write a program that will clean <a href="https://infohub.nyced.org/reports/school-quality/information-and-data-overview/end-of-year-attendance-and-chronic-absenteeism-data">district school attendance data</a> so that we can use the same visualization to see attendance for different districts.

<p>Your stand-alone program should ask the user for the input file name, the output file name, as well as the grade and school year to use as filters.  For example,
a sample run of the program on <a href="public-district-attendance-results-2014-2019.csv">public-district-attendance-results-2014-2019.csv</a>:
<pre><code class="blockcode">
Enter input file name: public-district-attendance-results-2014-2019.csv
Enter output file name: attendanceThirdGrade2019.csv
Enter grade: 3
Enter year: 2018-19
</code></pre>
If the input file starts as:
<pre><code class="datablock">
District,Grade,Year,Category,# Total Days,# Days Absent,# Days Present,% Attendance,# Contributing 20+ Total Days,# Chronically Absent,% Chronically Absent
1,All Grades,2013-14,All Students,2088851,187879,1900972,91.0,12617,3472,27.5
1,All Grades,2014-15,All Students,2064610,171200,1893410,91.7,12295,3160,25.7
1,All Grades,2015-16,All Students,1995704,169094,1826610,91.5,12137,3206,26.4
1,All Grades,2016-17,All Students,1946012,161756,1784256,91.7,11916,3110,26.1
1,All Grades,2017-18,All Students,1946527,167998,1778529,91.4,11762,3244,27.6
1,All Grades,2018-19,All Students,1925995,175153,1750842,90.9,11593,3364,29.0
</code></pre>
then the output file would start:
<pre><code class="datablock">
District,Grade,Year,Category,# Total Days,# Days Absent,# Days Present,% Attendance,# Contributing 20+ Total Days,# Chronically Absent,% Chronically Absent
1,3,2018-19,All Students,149871,10601,139270,92.9,876,228,26.0
2,3,2018-19,All Students,491432,21170,470262,95.7,2844,278,9.8
3,3,2018-19,All Students,254506,15395,239111,94.0,1488,274,18.4
</code></pre>


<p><i>Hints:
<ul>
    <li> In the CSV file, <code class="inline">Grade</code> can contain both numbers and strings.  Since <code class="inline">"3"</code> is different from the number <code class="inline">3</code>, you may want to convert to strings before comparison.</li>
    <li> The output CSV should not contain the internal index and should be saved without it.
</ul>
</i>

<!-- Folium tutorial:  https://autogis-site.readthedocs.io/en/latest/notebooks/L5/02_interactive-map-folium.html
Layers on folium:  https://blog.prototypr.io/interactive-maps-with-python-part-1-aa1563dbe5a9
https://automating-gis-processes.github.io/2017/lessons/L5/interactive-map-folium.html
Altair & choropleth:  https://www.districtdatalabs.com/altair-choropleth-viz-->

<p>
</p>

<p><a name="p17"><b>Program 17: Grouping ELA/Math by Districts.</b></b> &emsp; <i>Due noon, Friday, 1 October.</i>
  <br>(Learning Objective: to successfully combine information from multiple input files and display the results using a pivot table.)




  <p>Your program should build on the classwork from Lectures #6 and #9 to build a pivot table, grouped by district and test subject, of the percentage of students that are proficient in each (i.e. score 3 or 4 on the exam).  Your program should ask the user for two input CSV files and print a pivot table.
</p>


Then a sample run of the program with files truncated to a few schools per district for testing (<a href="ela_trunc.csv">ela_trunc.csv</a> and <a href="math_trunc.csv">math_trunc.csv</a>) starts as:

<pre><code class="blockcode">Enter file containing ELA scores: ela_trunc.csv
Enter file containing MATH scores: math_trunc.csv
                    Proficiency                      School Name
District Subject
01       ELA        91.891892  THE EAST VILLAGE COMMUNITY SCHOOL
         MATH       84.615385               P.S. 184M SHUANG WEN
02       ELA        96.825397           P.S. 77 LOWER LAB SCHOOL
         MATH       98.412698           P.S. 77 LOWER LAB SCHOOL
</code></pre>
and continues with top scoring schools for each test and each district printed.
</p>

<i>
<p>Hints:
  <ul>
    <li> Work first with the math scores and get those scores selected.  Then, repeat with the ELA scores.  Once both have the correct values, combine for the final answer.
    <li> Look at the names used in the row and column indices, and use similar names for your dataframes to avoid having to rename them later.
    <li> A very useful aggregate function is <code class="inline">idxmax()</code> which returns the index of the row where the maximum occurs, instead of just the value itself.  For example, if you had a DataFrame <code class="inline">mathdf</code> with the proficiency column already computed, the following will list all the columns for the school with the maximum profiency for each district:
  <pre><code class="blockcode">mathdf = mathdf.loc[ mathdf.groupby('District')['Proficiency'].idxmax() ]</code></pre>
</ul>
</p>
</i>


<p><a name="p18"><b>Program 18: Log Scale.</b></b> &emsp; <i>Due noon, Monday, 4 October.</i>
  <br>(Learning Objective: gain competency in scaling data via log transformations.)

  <p>
  In Lecture #9 and <a href="http://www.textbook.ds100.org/ch/10/viz_principles_2.html">Section 11.5</a>, we used log scale to visualize data.  Since the logarithm function is not defined on non-positive data, we are first going to write a function that removes any tuple that has a 0 or negative value.  Our second function transformed the cleaned data to its log values.

  <p>
  Write two functions that to be used to display data on a log-scale.  Each function takes and returns two iterables of numeric values (e.g. a Series, np.array, or list restricted to numeric values).

  Each function takes as input a row of the table:
  <ul>
    <li> <code class = "inline">dropNeg(xS,yS)</code>:  This function takes two iterables, <code class = "inline">xS</code> and <code class = "inline">yS</code> of numeric values.  If any entry is not positive in either iterable, that indexed value is dropped from both series.  The results are returned as two separate iterables.  To do this, first zip the series together, drop all the pairs with zero or negative values, and then unzip to return series with only positive values.

    <p>For example, if <code class = "inline">xS</code> contains
    <code class = "inline">[1,2,0,3,4]</code> and
    <code class = "inline">yS</code> contains <code class = "inline">[0,-1.5,4,3,9]</code>, then the <code class = "inline">zip(xS,yS)</code> has entries
    <code class = "inline">[(1,0),(1,-1.5),(0,4),(3,3),(4,9)]</code>.  Dropping all tuples that contain non-positive values yields
    <code class = "inline">[(3,3),(4,9)]</code>, and the unzipped results, <code class = "inline">[3,4]</code> and
    <code class = "inline">[3,9]</code>, are returned.

    <li> <code class = "inline">logScale(xS,yS)</code>:  This function assumes that the inputted iterables contain numeric values, are positive and not null, and returns the <code class = "inline">np.log</code> of each.
    For example, when applying this function to the inputs <code class = "inline">[3,4]</code> and
    <code class = "inline">[3,9]</code>, the function returns <code class = "inline">[1.098612, 1.386294]</code> and
    <code class = "inline">[1.098612,2.19722458]</code>.
  </ul>

<p>
  Note:  you should submit a file with only the standard comments at the top, and these two functions.  The grading scripts will then import your functions for testing.  A sample test program that assumes your program is called
  <code class = "inline">p18.py</code>
  and is <a href="test18.py">test18.py</a>.
</p>


<p><a name="p19"><b>Program 19: Smoothing with Gaussians.</b></b> &emsp; <i>Due noon, Tuesday, 5 October.</i>
  <br>(Learning Objective: increase understanding of smoothing and gain fluidity with using distributions for smoothing.)


  <p>
  In Lecture #9 and <a href="http://www.textbook.ds100.org/ch/10/viz_principles_2.html">Section 11.5</a>, we used smoothing to visualize data.  For this program, write a function that takes two arguments, an Numpy array of x-axis coordinates, and a list of numeric values, and returns the corresponding y-values for the sum of the gaussian probability distribution functions (pdf's) for each point in the list.

  <ul>
    <li> <code class = "inline">computeSmoothing(xes,points)</code>:  This function takes a numpy array <code class = "inline">xes</code> and a list, <code class = "inline">points</code>, of numeric values.  For each <code class = "inline">p</code> in <code class = "inline">points</code>, the function should compute the normal probability distribution function (<code class = "inline">scipy.norm.pdf</code>)
    centered at <code class = "inline">loc = p</code> with standard deviation <code class = "inline">scale = 0.5</code> for all values in <code class = "inline">xes</code>.  The return value is a numpy array of the sum of these at each point.
  </ul>

  <p>For example, calling the function:
    <pre><code class="blockcode">xes = np.linspace(0, 10, 1000)
density = computeSmoothing(xes,[5])
plt.plot(xes,density)
plt.show()</code></pre>

    would give the plot:

    <p><img height=200 src="density5.png">

    <p>since there is only one point given (namely 5), the returned value is the probability density function centered at 5 (with <code class = "inline">scale =  0.5</code>) computed for each of the <code class = "inline">xes</code>.

<p>For example, calling the function:
  <pre><code class="blockcode">pts = [2,2,5,5,2,3,4,6,7,9]
xes = np.linspace(0, 10, 1000)
density = computeSmoothing(xes,pts)
plt.plot(xes,density)
plt.fill_between(xes,density)
plt.show()</code></pre>

would give the plot:

<p><img height=200 src="density_fillBetween.png">

  <p>since the there are 10 points given, the function computes the probability density function centered at each of the points, across all the values in <code class = "inline">xes</code>.  It then sums up these contributions and returns an array of the same length as <code class = "inline">xes</code>.




<p>
    Note:  you should submit a file with only the standard comments at the top, and this function.  The grading scripts will then import your function for testing.

<p>
  <i>Hint:  Include only the function you need (such as <code class = "inline">numpy</code> and <code class = "inline">scipy.stats</code>) and none of the ones for plotting (such as <code class = "inline">matplotlib.pyplot</code> and <code class = "inline">seaborn</code>) since this function is computing and not plotting.
  </i>
  </p>


  <br>
  <br>
  <br>
  <hr>
  Set 4:  The fourth set of programs introduces modeling and estimation, focusing on loss functions and linear modeling.
  <hr>


<p><a name="p20"><b>Program 20: Loss Functions for Tips.</b></b> &emsp; <i>Due noon, Thursday, 7 October.</i>
    <br>(Learning Objective: strengthen competency with loss functions by applying the techniques to a dataset of tips.)
    <p>
    </p>
    In Lecture #10 and <a href="http://www.textbook.ds100.org/ch/04/modeling_loss_functions.html">Section 4.2</a>, we introduced loss functions to measure how well our estimates fit the data.

    <p>
    Using the functions mean squared loss function <code class = "inline">mse_loss</code> and mean absolute loss function <code class = "inline">abs_loss</code> (<a href="http://www.textbook.ds100.org/ch/04/modeling_loss_functions.html">Section 4.2</a>),
    write two separate functions that take in estimates and tip data
    and returns the respective loss function for each of the estimates to the data.

    <ul>
      <li> <code class = "inline">mse_estimates(thetas,tips)</code>:  This function takes two iterables of numeric values:
      <ul>
          <li> <code class = "inline">thetas</code>: estimates for the population parameter for the percent tips in <code class = "inline">values</code>, and
          <li> <code class = "inline">tips</code>: the tips observed, assumed to be a  positive percentage, ranging from 0 to 100.
      </ul>
      For each <code class = "inline">theta</code> in <code class = "inline">thetas</code>, it should compute the mean squared error between <code class = "inline">theta</code> and <code class = "inline">tips</code>. Return an iterable of the values computed.

      <li> <code class = "inline">mae_estimates(thetas,tips)</code>:  This function takes two iterables of numeric values:
        <ul>
            <li> <code class = "inline">thetas</code>: estimates for the population parameter for the percent tips in <code class = "inline">values</code>, and
            <li> <code class = "inline">tips</code>: the tips observed, assumed to be a  positive percentage, ranging from 0 to 100.
        </ul>
      For each <code class = "inline">theta</code> in <code class = "inline">thetas</code>, it should compute the mean absolute error between <code class = "inline">theta</code> and <code class = "inline">tips</code>. Return an iterable of the values computed.

    </ul>

    Note:  for each of these functions, your returned value will be an iterable with the same length as <code class = "inline">thetas</code>.

    <p>For example, calling the function:
      <pre><code class="blockcode">thetas = np.array([12, 13, 14, 15, 16, 17])
y_vals = np.array([12.1, 12.8, 14.9, 16.3, 17.2])
mse_losses = p20.mse_estimates(thetas,y_vals)
abs_losses = p20.mae_estimates(thetas,y_vals)
plt.scatter(thetas, mse_losses, label='MSE')
plt.scatter(thetas, abs_losses, label='MAE')
plt.title(r'Loss vs. $ \theta $ when $ \bf{y}$$= [ 12.1, 12.8, 14.9, 16.3, 17.2 ] $')
plt.xlabel(r'$ \theta $ Values')
plt.ylabel('Loss')
plt.legend()
plt.show()</code></pre>

      would give the plot:

      <p><img height=200 src="loss_small_ex.png">

  <p>For example, calling the function:
    <pre><code class="blockcode">thetas = np.arange(30)
tips_df = sns.load_dataset('tips')
tipsPercent = (tips_df['tip']/tips_df['total_bill'])*100
mse_losses = p20.mse_estimates(thetas, tipsPercent)
abs_losses = p20.mae_estimates(thetas, tipsPercent)
plt.plot(thetas, mse_losses, label='MSE')
plt.plot(thetas, abs_losses, label='MAE')
plt.title(r'Loss vs. $ \theta $ for sns tips data')
plt.xlabel(r'$ \theta $ Values')
plt.ylabel('Loss')
plt.legend()
plt.show()</code></pre>

  would give the plot:

  <p><img height=200 src="loss_tips.png">

  <p>
      Note:  you should submit a file with only the standard comments at the top, and this function.  The grading scripts will then import your function for testing.

  <p>
    <i>Hint:  Include only the libraries you need (such as <code class = "inline">numpy</code>) and none of the ones for plotting (such as <code class = "inline">matplotlib.pyplot</code> and <code class = "inline">seaborn</code>) since this function is computing and not plotting.
    </i>
    </p>


<p><a name="p21"><b>Program 21: Taxi Cleaning.</b></b> &emsp; <i>Due noon, Friday, 8 October.</i>
  <br>(Learning Objective: To build up (or refresh) skills at manipulating tabular data, in particular, to use arithmetic operations on columns to create new columns.)

  <p>
    Write a program, tailored to the NYC OpenData Yellow Taxi Trip Data, that asks the user for the name of an input CSV file and the name of an output CSV file.  The program should open the file name provided by the user. Next, the program should copy the input file and create two new columns:  <code class="inline">percent_tip</code>, which is <code class="inline">100*tip_amount/fare_amount</code> and <code class="inline">percent_fare</code>, which is <code class="inline">100*fare_amount/total_amount</code>.  Your program should write out a new CSV file (with the name provided by the user) with the original columns as well as the two newly computed ones.

    <p>For example, if the file, <a href="taxi_new_years_day_2020.csv">taxi_new_years_day_2020.csv</a>, was the first of January 2020 entries downloaded from <a href="https://data.cityofnewyork.us/Transportation/2020-For-Hire-Vehicles-Trip-Data/m3yx-mvk4">2020 Yellow Taxi Trip Data</a> (about 170,000 entries) with the first 3 lines of:
<pre><code class="datablock">VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge
1,01/01/2020 12:00:00 AM,01/01/2020 12:13:03 AM,1,2.2,1,N,68,170,1,10.5,3,0.5,2.85,0,0.3,17.15,2.5
2,01/01/2020 12:00:00 AM,01/01/2020 01:08:55 AM,5,1.43,1,N,48,239,2,6.5,0.5,0.5,0,0,0.3,10.3,2.5
</code></pre>
    Then a sample run of the program:
<pre><code class="blockcode">Enter input file name: taxi_new_years_day2020.csv
Enter output file name:  taxi_Jan2020_with_percents.csv
</code></pre>

    And the first three lines of <tt>taxi_Jan2020_with_percents.csv</tt> would be:
<pre><code class="datablock">VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge,percent_tip,percent_fare
1.0,01/01/2020 12:00:00 AM,01/01/2020 12:13:03 AM,1.0,2.2,1.0,N,68,170,1.0,10.5,3.0,0.5,2.85,0.0,0.3,17.15,2.5,27.1,61.2
2.0,01/01/2020 12:00:00 AM,01/01/2020 01:08:55 AM,5.0,1.43,1.0,N,48,239,2.0,6.5,0.5,0.5,0.0,0.0,0.3,10.3,2.5,0.0,63.1
</code></pre>
    <p> You should round the values stored in your new columns to the nearest tenth and save your CSV file without the indexing (i.e. <code class="inline">index=False</code>).

  </p>


<p><a name="p22"><b>Program 22: Dice Simulator.</b></b> &emsp; <i>Due noon, Thursday, 14 October.</i>
    <br>(Learning Objective: students will be able to apply their knowledge of the built-in random package to generate simulations of simple phenomena.)
    <p>

    Write a function:
    <ul>
        <li> <code class="inline">diceSim(D1,D2,trials)</code> that takes as input the number of sides on die 1 (<code class="inline">D1</code>) and
        die2 (<code class="inline">D2</code>) and the number of trials.  Your function should repeatedly sum pairs of random numbers between 1 and <code class="inline">D1</code> and 1 and <code class="inline">D2</code> and keep track of how many times each sum occurs. The function returns a numpy array with the fraction each sum of rolls occured.
      </ul>

      <p>
      Since the numbers are chosen at random, the fractions will differ some from run to run. One run of the function <code class="inline">print(p22.diceSim(6,6,10000))</code> resulted in:
<pre><code class="datablock">
  [0.     0.     0.0259 0.0615 0.0791 0.1086 0.139  0.1633 0.1385 0.114  0.0833 0.0587 0.0281]</code></pre>

      or displayed using the code from <a href="http://www.textbook.ds100.org/ch/15/prob_random_vars.html">Section 15.1.1.</a>:
      <p>
      <img src="dice_6_6.png" height=200>
      </p>
      <p>
      Note:  you should submit a file with only the standard comments at the top and the function.  The grading scripts will then import your function for testing.
      </p>

<!--
<p><a name="p23"><b>Program 23: PMF of Senators' Ages.</b></b> &emsp; <i>Due noon, Friday, 15 October.</i>
    <br>(Learning Objective: strengthen competency with probability mass functions by analysing ages of public officials.)
    <p>
    Echo the chapter on PMF's but instead use an input file (already have senators' ages calculated from above).  Write as a function?  Use book's plotting function.
    </p>

<p><a name="p24"><b>Program 24: Fitting LM's to Taxi Data.</b></b> &emsp; <i>Due noon, Monday, 18 October.</i>
    <br>(Learning Objective: ????.)
    <p>
    Run the linear model with a single parameter on a parameter specified by user.  Set up as a function?  Use the book's plotting to display.  Give small sample file to test on.

    Taxi Models.
    In classwork, work through sklearn linear_model & linear regression.  In this program, apply to restaurant tip data.
    </p>

<p><a name="p25"><b>Program 25: .</b></b> &emsp; <i>Due noon, Tuesday, 19 October.</i>
    <br>(Learning Objective: .)
    <p>
    </p>

<p><a name="p26"><b>Program 26: .</b></b> &emsp; <i>Due noon, Thursday, 21 October.</i>
    <br>(Learning Objective: .)
    <p>  </p>

<p><a name="p27"><b>Program 27: MLM's for Taxi Trips.</b></b> &emsp; <i>Due noon, Friday, 22 October.</i>
    <br>(Learning Objective: .)
    <p>
    Run the linear model with multiple parameters to build a better model of taxi tips.  Program should ask for input file and return as a file.  Give small sample file to test on.
    </p>



<p><a name="p43"><b>Program 43: Component Retention.</b></b> &emsp; <i>Due noon, Friday, 19 November.</i>
    <br>(Learning Objective: to employ programming skills to evaluate the number of principal components to use in dimensionality reduction.)</p>
    <p>
    In lecture and (also in <a href="http://www.textbook.ds100.org/ch/25/pca_in_practice.html">Chapter 25</a>), we used scree plots to provide a visualization of the captured variance.  This assignment asks you to implement two other popular ways of determining the number of dimensions to retain.

    <ul>
      <li> <code class="inline">captures85(arr):</code> Takes an array <code class="inline">arr</code> (in decreasing order), computes
          the captured variance (<code class="inline">cv = (arr**2)/sum(arr**2)</code>) and returns the number of elements needed to capture more than 85% of the variance.  Using the example from the textbook, if <code class="inline">arr</code> is
<pre><code class="datablock">array([585.57, 261.06, 166.31,  57.14,  48.16,  39.79,  31.71,  28.91,
24.23,  22.23,  20.51,  18.96,  17.01,  15.73,   7.72,   4.3 ,
1.95,   0.04])</code></pre>
          Then <code class="inline">cv</code> would be:
<pre><code class="datablock">array([0.76, 0.15, 0.06, 0.01, 0.01, 0.  , 0.  , 0.  ,   0.  , 0.  , 0.  ,
       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ])</code></pre>
          and the function would return 2 since the first coordinate captures 76% of the variance which is less than 85%, the first 2 coordinates capture 76 + 15 = 91% of the variance.
      <li> <code class="inline">averageEigenvalue(arr):</code> Takes an array
        <code class="inline">arr</code> (in decreasing order), computes
          the average (<code class="inline">avg = sum(arr)/len(arr)</code>) and returns the number of elements greater than <code class="inline">avg</code>.  Using the example from the textbook, if <code class="inline">arr</code> is:
          <pre><code class="datablock">array([585.57, 261.06, 166.31,  57.14,  48.16,  39.79,  31.71,  28.91,
        24.23,  22.23,  20.51,  18.96,  17.01,  15.73,   7.72,   4.3 ,
         1.95,   0.04])</code></pre>
          Then <code class="inline">avg</code> would be 75.07,
          and the function would return 3 since the first three coordinates are larger than the average.
    </ul>

    </p>
    <p>
    Note:  you should submit a file with only the standard comments at the top, and these two functions.  The grading scripts will then import your functions for testing.


<p><a name="p44"><b>Program 44: Digits Components.</b></b> &emsp; <i>Due noon, Monday, 22 November.</i>
    <br>(Learning Objective: .)</p>
    <p>
    In lecture, we introduced Principal Components Analysis and the number of components needed to capture the intrinistic dimension of the data set.  For this program, write a function that allows the user to explore how many dimensions are needed to see the underlying structure of images from the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html">sklearn digits dataset</a> (inspired by <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html">Python Data Science Handbook: Section 5.9</a> (PCA)).
    <p>
    <a href="https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py">
      <img src="sklearn_digits.png" height=400>
    </a>
    <p>
    </p>








<p><a name="p28"><b>Program 28: .</b></b> &emsp; <i>Due noon, Monday, 25 October.</i>
  <br>(Learning Objective: .)
  <p>
  </p>

<p><a name="p29"><b>Program 29: .</b></b> &emsp; <i>Due noon, Tuesday, 26 October.</i>
  <br>(Learning Objective: .)
  <p>
  </p>

<p><a name="p30"><b>Program 30: .</b></b> &emsp; <i>Due noon, Thursday, 28 October.</i>
  <br>(Learning Objective: .)
  <p>
  </p>

<p><a name="p31"><b>Program 31: .</b></b> &emsp; <i>Due noon, Friday, 29 October.</i>
  <br>(Learning Objective: .)
  <p>
  </p>

<p><a name="p32"><b>Program 32: .</b></b> &emsp; <i>Due noon, Monday, 1 November.</i>
  <br>(Learning Objective: .)
  <p>
  </p>

<p><a name="p33"><b>Program 33: .</b></b> &emsp; <i>Due noon, Tuesday, 2 November.</i>
  <br>(Learning Objective: .)
  <p>
  </p>

<p><a name="p34"><b>Program 34: .</b></b> &emsp; <i>Due noon, Thursday, 4 November.</i>
  <br>(Learning Objective: .)
  <p>
  </p>

<p><a name="p35"><b>Program 35: .</b></b> &emsp; <i>Due noon, Friday, 5 November.</i>
  <br>(Learning Objective: .)</p>
  <p>
  </p>

  --------- Regression on Probabilities; The Logistic Model

  # P35
  import data
  create your own Y = 0, 1 from a continuous Y variable (?)
  value_counts of Y
  cross tabulate against X1, X2, etc. -> visualize as table

<p><a name="p36"><b>Program 36: .</b></b> &emsp; <i>Due noon, Monday, 8 November.</i>
  <br>(Learning Objective: .)</p>
  <p>
  </p>

  # P36
  same data as P35
  plot (jittered) Y against each X
  draw sigmoid?  or just conceptualize when this is different from linear

<p><a name="p37"><b>Program 37: .</b></b> &emsp; <i>Due noon, Tuesday, 9 November.</i>
  <br>(Learning Objective: .)</p>
  <p>
  </p>

  --------- A Loss Function for the Logistic Model; Using Logistic Regression

  # P37
  fit a simple logistic regression using out of box:
  from sklearn.linear_model import LogisticRegression
  Y ~ X1
  compare accuracy of this against accuracy of always predicting 0 or 1

<p><a name="p38"><b>Program 38: .</b></b> &emsp; <i>Due noon, Thursday, 11 November.</i>
  <br>(Learning Objective: .)</p>
  <p>
  </p>

  # P38
  using same data as P37, do train/test split (with seeding)
  Y ~ X1 + X2 ... (possibly with one-hot encoding)
  compare accuracy of this against bsaeline of always predicting 0 or 1
  compare accuracy of test vs train

<p><a name="p39"><b>Program 39: .</b></b> &emsp; <i>Due noon, Friday, 12 November.</i>
  <br>(Learning Objective: .)</p>
  <p>
  </p>

  --------- Approximating the Empirical Probability Distribution; Fitting a Logistic Model

  # P39
  train/test split
  fit logistic regression
  compute accuracy, precision, recall
  record CPU time and wall time

<p><a name="p40"><b>Program 40: .</b></b> &emsp; <i>Due noon, Monday, 15 November.</i>
  <br>(Learning Objective: .)</p>
  <p>
  </p>

  # P40
  same data as P39
  train/test split
  fit stochastic gradient descent
  tune hyperparameters (are we doing different search methods?)
  compare results to P39.  which one would you choose?

<p><a name="p41"><b>Program 41: .</b></b> &emsp; <i>Due noon, Tuesday, 16 November.</i>
  <br>(Learning Objective: to use the tools provided by sklearn to create a binary logit classifer.)</p>
  <p>
  </p>

  --------- Evaluating Logistic Models; Multiclass Classification

  P41
  re-use one of the previous examples to create a binary logit classifier
  then use sklearn built in functions to calculate confusion matrix
  also use sklearn built in functions to calculate and then plot AUC



<p><a name="p42"><b>Program 42: .</b></b> &emsp; <i>Due noon, Thursday, 18 November.</i>
  <br>(Learning Objective: to create a multilabel classifer using sklearn.)</p>
  <p>
  </p>

  P42
  create a multilabel classifier
  use sklearn built in functions to calculate confusion matrix and AUC
  but then ... write your OWN function to output the exact same confusion matrix & AUC (too much?)


  <p><a name="p45"><b>Program 45: Mystery Point.</b></b> &emsp; <i>Due noon, Tuesday, 23 November.</i>
      <br>(Learning Objective: .)</p>
      <p>
      </p>
Links to sklearn MDS:  https://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html
https://scikit-learn.org/stable/auto_examples/manifold/plot_mds.html

How much do we want to go into affine transformations?
https://stackabuse.com/affine-image-transformations-in-python-with-numpy-pillow-and-opencv/
https://en.wikipedia.org/wiki/Transformation_matrix#Affine_transformations

  <p>
  </p>



<p><a name="p46"><b>Program 46: .</b></b> &emsp; <i>Due noon, Monday, 29 November.</i>
  <br>(Learning Objective: .)</p>
    <p>
    </p>

<p><a name="p47"><b>Program 47: .</b></b> &emsp; <i>Due noon, Tuesday, 30 November.</i>
    <br>(Learning Objective: .)</p>
    <p>
    </p>

<p><a name="p48"><b>Program 48: .</b></b> &emsp; <i>Due noon, Thursday, 2 December.</i>
        <br>(Learning Objective: .)</p>
        <p>
        </p>

<p><a name="p49"><b>Program 49: .</b></b> &emsp; <i>Due noon, Friday, 3 December.</i>
  <br>(Learning Objective: .)</p>
  <p>
  </p>

<p><a name="p50"><b>Program 50: .</b></b> &emsp; <i>Due noon, Monday, 6 December.</i>
  <br>(Learning Objective: .)</p>
  <p>
  </p>
-->

<!--






P5:

<p>Ideas:
<pre>

Wait on the background for the Obama v. Romney, and instead have a several data cleaning example just using string methods.  One that needs to check for empty entries.  Another that combines multiple columns into a new one.  maybe the 311 or NYPD data (since often missing GIS coordinates).

To lead into lecture #3:  sample vs. census of a large data set-- book uses Obama vs. Romney.  Add in a question about cluster and stratified sampling?  Wait until random packages discussed?  Or just use the basic Python one?

Need several questions on correlation-- maybe set 3 or 4?
From Lehman's DS course:  HW5:  Are collisions correlated with temperature?

A/B Testing-- do as part of quizzes when we do Bayes Theorem

#6: Modify the Naive Bayes spam filter program to reads in the three files generated above as well as a fourth file of test data (use another year's data such as yob2010.txt). Instead of multiplying together word occurrences, your program should multiply use the last letter, second-to-last letter, and third-to-last letter that you computed above. Your program should classify each name in the test data (similar to the Naive Bayes filter from the book) and report back the percentage of names your correctly predicted as well as the names you predicted incorrectly.
Submit your Python program as a .py file.

Covariance:  HW 9:  Analyse the NY Fed's Labor Market Data for Recent Graduates (see link above) using a Principal Components Analysis. There are three parts to this exercise:
Compute and display the covariance matrix for the data,
Generate a 3D plot of the data under the first three axis of a Principal Components Analysis. On this plot, highlight (using a different color) the computer science and mathematics majors, and
Include the Python code that you used to generate your plots.
Make sure to include in the title of your plot the date plotted.

Using the New York City data for district test scores, shade your map above by percentage of students proficient in mathematics (i.e. scored a 3 or 4 on the exam-- the last column in the CSV file).

#6: Using the New York City data for district test scores, compute the covariance matrix for District 1 schools across grades (that is, rows 8 to 28, columns G onward). Which rows are most highly correlated? Submit a typeset or neatly handwritten image of your answer.</i>

When do mapping, something with litter baskets:  https://data.cityofnewyork.us/dataset/DSNY-Litter-Basket-Map-/d6m8-cwh9

Need some programs on displaying, time-series data, something like the standard stocks example.  Here's bokeh: https://docs.bokeh.org/en/0.10.0/docs/gallery/stocks.html
Find on altair

HW 12:  The file landmarkDistances.txt contains a distance matrix for 10 landmarks in New York City. The file landmarks.txt contains the names of 9 of the landmarks. The last name is "mystery". Use multidimensional scaling to display all 10 points on the screen with landmarks labeled. Using your displayed information, identify the last mystery landmark.
(Based on the inspired homework from dasGupta's machine learning course at UCSD.)


HW 12:  Using the 311 Pothole data (described above), use logistic regression analysis of time versus status: "Closed" versus "Open" (any non-"Closed" values of the status include in the "Open" category) to create a model that predicts if a pothole has been repaired, given the date reported.
You may want to use the textbook's code (described above)-- if you do, modify to take only 1 input parameter (instead of the 2 it currently takes). This is a very small change (just change the starting beta_0 to match the dimension of the data and be [1,1].)

HW 12:  Modeling question-- not sure when to integrate into topics:
Given the data:
x	0	1	2	4	5	7	8	9	12	15
y	0	0	0	1	1	0	1	0	1	1

and two possible logistic functions:

f(x) = 1/(1 +e^{-(6+.75x)})
g(x) = 1/(1 +e^{-(-8+x)})
#6: Which function predicts more of the data correctly? That is, out of the 10 input values, how many values were predicted to be 1 with greater than 50% probability were actually 1 (true positives), were actually 0 (false positives); how many values were predicted to be 0 with greater than 50% probability were actually 0 (true negatives), were actually 1 (false negatives)?

#7: Use the book's logistic regression code to fit a logistic function to the data above.
Note: The book's code assumes that 3 dimensional data while we have only 2 dimensions. The code is well-written and can be easily modified to handle only 2 dimensions by entering 2 dimensional data for data and modifying the starting value of beta_0 to be the [1,1].

Submit a screenshot of a graph with the true points, your predicted curve (i.e. the logistic function with your computed beta_hat, and the f and g functions above. Include a legend or labels for your curves.

<p><i>Extras:</i>  These problems are not submitted or graded, but are suggestions for those who would like more Python experience or more practice on the concepts of the section.  These problems also have possible tools for the course project and practice for quizzes and the final exam.

<ul>
  <li>List Comprehensions:</li>
  <li>Functions & Pandas: Using apply(), manipulating DataFrames  </li>
  <li>Matplotlib Basics:</li>
  <li>Seaborn:</li>
  <li>String Methods:</li>
  <li>Loss Functions:</li>
  <li>Lambda Functions:</li>
  <li>Unpacking Argument Lists & Keywords:</li>
</ul>

Include in each data set a prediction question (building on tools known at the time)-- focus on NYC data, leading up to more open-ended (aka Kaggle-style) one in November/December

-->
<br><br>
  <p>
    <i>More to come...</i>

<br><br><br><br><br><br>
<hr>
<a name="project">
<h2>Project</h2>
</a>

<p>
The required final project synthesizes the skills acquired in the course to analyze and visualize data on a topic of your choosing.  It is your chance to demonstrate what you have learned, your creativity, and a project that you are passionate about.  The intended audience for your project is your classmates as well as tech recruiters and potential employers.

</p>

<h3>Milestones</h3>

The project is broken down into smaller pieces that must be submitted by the deadlines below.  For details of each milestone, see the links.  The project is worth 25% of the final grade.  The point breakdown is listed in the right hand column.


<p>
<table class="handouts" border="1">
<tr>
	<th>Deadline:</th><th>Deliverables:</th><th>Points:</th><th>Submitted Via:</th>
</tr>
<tr>
	<td>Wednesday, 6 October, noon</td>
  <td><a href="#preproposal">Pre-Proposal</a></td>
  <td>15</td>
  <td>Gradescope</td>
</tr>
<tr>
	<td>Wednesday, 13 October, noon</td>
  <td><a href="#proposal">Title & Proposal</a></td>
  <td>20</td>
  <td>Blackboard</td>
</tr>
<tr>
	<td>Wednesday, 20 October, noon</td>
  <td><a href="#peerReview">Peer Review #1</a></td>
  <td>15</td>
  <td>Blackboard</td>
</tr>
<tr>
	<td>Wednesday, 3 November, noon</td>
  <td><a href="#dataCollection">Check-in #1 (Data Collection)</a></td>
  <td>20</td>
  <td></td>
</tr>
<tr>
	<td>Wednesday, 10 November, noon</td>
  <td><a href="#analysis">Check-in #2 (Analysis)</a></td>
  <td>20</td>
  <td></td>
</tr>
<tr>
	<td>Wednesday, 17 November, noon</td>
  <td><a href="#visualization">Check-in #3 (Visualization)</a></td>
  <td>20</td>
  <td></td>
</tr>

<tr>
	<td>Wednesday, 1 December, noon</td>
  <td><a href="#slides">Draft Abstract & Website</a></td>
  <td>25</td>
  <td></td>
</tr>
<tr>
	<td>Monday, 6 December, noon</td><td>
  <a href="#peerReview2">Peer Review #2</a></td>
  <td>15</td>
  <td>Blackboard</td>
</tr>

<tr>
	<td>Thursday, 9 December, noon</td>
  <td><a href="#abstract">Abstract</a></td>
  <td>25</td>
  <td></td>
</tr>

<tr>
	<td>Friday, 10 December, noon</td>
  <td><a href="#completeSite">Complete Project Website</a></td>
  <td>50</td>
  <td></td>
</tr>


<tr>
	<td>Monday, 13 December, noon</td><td><a href="#presentation">Project Video</a></td><td>25</td>
  <td>Blackboard</td>
</tr>
<tr>
	<th colspan=2>Total Points:</th>
  <td>250</td>
  <td></td>
</tr>


</table>


<br><br>
<h3>Pre-Proposal</h3>
<a name="preproposal"></a>

This pre-proposal is meant to guide you as you brainstorm about your project.  It will also lead up to a more formal and structured project proposal later on.  The window for submitting pre-proposals opens Wednesday, 22 September.  If you would like feedback and the opportunity to resubmit for a higher grade, submit early in the window. Feel free to re-submit as many times as you like, up until the assignment deadline.  The instructing team will work hard to give feedback on your submission as quickly as possible, and we will grade them in the order they were received.


<p> In the pre-proposal, answer each question with 1 to 2 sentences:

<ul>
  <li> <b>Overview:</b> Describe your project in layman terms.  Think of this as an <a href="https://en.wikipedia.org/wiki/Elevator_pitch">elevator pitch</a>.</li>

  <li> <b>Importance:</b> Describe why this project has personal significance to you.</li>

  <li> <b>Originality:</b> Describe why you believe this project idea is unique and original.</li>

  <li> <b>Methods:</b> Describe how you are planning to apply the data science skills you learned in this class to this project.</li>

  <li> <b>Data:</b> What dataset(s) are you thinking of using?</li>

</ul>

<!--
<h3>Pre-Proposal</h3>
<a name="preproposal"></a>


<h3>Title & Proposal</h3>
<a name="proposal"></a>


A short statement that includes:
<ul>
	<li> Proposed topics or questions you would like to address,
	<li> Why you are interested in this topic (in your own words-- copying someone else's words is plagiarism),
	<li> What data sets you plan to use (must use at least 2 distinct data sets per team member in meaningful ways in your project), and
	<li> What techniques and tools you are thinking about using.
</ul>


<h3>Timeline</h3>
<a name="timeline"></a>

<p>
Your plan of attack to complete this project on time, including what you will have completed by the check-ins for Data Collection, Analysis, and Visualization.  You should view the timeline as a contract with specifics of what the "deliverables" are at each milestone.

<p>
<ul>
</ul>

<h3>Presentation Slides</h3>
<a name="slides"></a>

REWRITE-- need 30 second preview (recorded) + grading rubric of others?  Maybe have feed back from other students earlier in the process?


The presentation .  The first part consists of a "sneak preview" of your project where your group speaks for 90 seconds about what they did.  After every group has given their sneak preview, each group will display their project on a lab computer (see below for more details).

<p>
For the sneak preview, every group submits 2 slides with
<ul>
	<li> Slide 1: the front image and title from website, as well as the names of group members
	<li> Slide 2:  discoveries & conclusions (with images)
</ul>
</div>

<div>
<h3>Data Collection</h3>
<a name="slides"></a>

<p>
For the data collection milestone, you must submit:
<ul>
	<li> a list (with links) of all data sources used,
	<li> for each data source:
		<ul>
			<li> a description of what and why you are using that source,
			<li> how you extracted the data from the source (i.e. detail how you downloaded/scraped the data as well as the file processing needed), and
			<li> any issues you had or forsee with the analysis of the data.
		</ul>
</ul>


</div>

<div>
<h3>Analysis</h3>
<a name="slides"></a>

<p>
For the analysis milestone, you must submit:
<ul>
	<li> the results of the initial analysis for each data set, and
	<li> details of at least one data set per group member (that is, each group member submits the details of a different data set used).
</ul>

</div>

<div>
<h3>Visualization</h3>
<a name="slides"></a>

<p>
For the visualization milestone, you must submit:
<ul>
	<li> draft images that you plan to use in your project presentation, and
	<li> detailed description of the creation of at least one image per group member (that is, each group member submits the details of a different image from the project).
</ul>

</div>

<div>
<h3>Complete Project</h3>
<a name="complete"></a>

<p> The project must be submitted as a webpage (use google sites or other pre-built if you're not comfortable writing html).  The project website must include:
<ul>
	<li> a front image and title that summarizes your project,
	<li> an overview paragraph on what you did:  what was your underlying hypothesis?  what data, methods, and tools did you use to test and explore it?
	<li> links to your github repository with your code for the project,
	<li> a team section describing how each person contributed to the project,
	<li> a data section with a paragraph detailing each data set,
	<li> a techniques section with a paragraph detailing,
	the process and tools you usedeach technique use,
	<li> a citations section with links to all data sources, code sources, publications used.
</li>
</div>


<div>
<h3>Project Presentation Video</h3>
<a name="presentation"></a>

<p>
The project presentations are on the last day of class and consist of two parts:
<ul>
	<li> 90 second sneak preview of your project (slide requirements described above), and
	<li> interactive demo (on lab computers) where each group member explains the overall process of creating the project as well as their individual contributions.

</div>

<div>
<h3>Grading</h3>


<p>
Half of the points are awarded for the work-in-process milestones during the semester, and half are awarded for the final project and presentation.

<h3>Examples</h3>

<p>
This course has not been taught at Lehman College before, so, no previous student projects exist.  Below is a sampled list of stellar student projects from other data science programs:
<ul>
	<li> <a href="http://cs109hubway.github.io/classp/">Predicting Hubway (Boston's Citibike) Station Status</a>:  a group project from Harvard's data science class.  Includes excellent presentation of the motivation as well as data visualizations.
	<li> <a href="http://www.michaelhintze.com/tv-series/">Longest Running TV Series</a>:  a class project by Lehman alum, Michael Hintze, for one of his masters courses at <a href="http://www.ischool.berkeley.edu/courses/i247">UC Berkeley School of Information</a>.
	<li> <a href="http://isoscope.martinvonlupin.de">Isoscope</a>:  a group project comparing modes of transportation for the masters degree program at the <a href="http://idl.fh-potsdam.de">University of Applied Sciences, Potsdam, Germany</a>.

</ul>
-->

<p>
  <i>More to come...</i>

</div>
</body>
</html>
